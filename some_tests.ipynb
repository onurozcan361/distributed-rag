{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asgrich/anaconda3/envs/big-data/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "25/04/04 16:53:23 WARN Utils: Your hostname, asgrich-laptop resolves to a loopback address: 127.0.1.1; using 192.168.1.105 instead (on interface wlp0s20f3)\n",
      "25/04/04 16:53:23 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/04 16:53:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "import subprocess\n",
    "import weaviate\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from scripts import weaviate_utils\n",
    "\n",
    "\n",
    "input_schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"ip\", StringType(), True),\n",
    "    StructField(\"port\", StringType(), True),\n",
    "    StructField(\"query\", StringType(), True),\n",
    "])\n",
    "\n",
    "output_schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"ip\", StringType(), True),\n",
    "    StructField(\"port\", StringType(), True),\n",
    "    StructField(\"rag_text\", StringType(), True),\n",
    "    StructField(\"confidence\", FloatType(), True),\n",
    "])\n",
    "\n",
    "vector_schema = ArrayType(FloatType())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"weaviate_deneme\").getOrCreate()\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "services = weaviate_utils.get_external_ips()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(query: str) -> list:\n",
    "    try:\n",
    "        q_embedding = embedding_model.encode(query).tolist()\n",
    "        return q_embedding\n",
    "    except Exception as e:\n",
    "        print(f\"err: {e}\")\n",
    "        return []\n",
    "\n",
    "generate_embedding_udf = F.udf(generate_embedding, vector_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_weaviate(cluster_name: str, cluster_ip: str, cluster_port: str, query_vector: list) -> dict:\n",
    "    try:\n",
    "        ## cluster baglantisi\n",
    "        client = weaviate.connect_to_custom(    \n",
    "            url=f\"http://{cluster_ip}:{cluster_port}\",\n",
    "            port=cluster_port,\n",
    "            scheme='http',\n",
    "            grpc_port=50051,  ## burasi defaultmus amk\n",
    "            grpc_scheme='http'\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        ## burayi editleyecegim indexlere gore, for loop gerekebilir\n",
    "        result = (\n",
    "            client.query.get(\"dist-data\", [\"blabla\", \"blabla\"])\n",
    "            .with_near_vector({\"vector\": query_vector})\n",
    "            .do()\n",
    "        )\n",
    "\n",
    "        client.close()\n",
    "\n",
    "        ## burasi da degisecek siteden aldigim gibi kaldi\n",
    "        if \"data\" in result and \"Get\" in result[\"data\"] and \"blabla\" in result[\"data\"][\"Get\"]:\n",
    "            top_results = result[\"data\"][\"Get\"][\"blabla\"]\n",
    "\n",
    "            rag_text = []\n",
    "            certainity = []\n",
    "            \n",
    "        else:\n",
    "            rag_text = []\n",
    "            certainity = []\n",
    "\n",
    "        ## ilk 5'i sec certainity'lere gore, ve ona gore gonder\n",
    "\n",
    "        return rag_texts, certainities\n",
    "\n",
    "\n",
    "search_weaviate_udf = F.udf(search_weaviate, output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+----+-----------+--------------------+\n",
      "|              name|            ip|port|      query|     query_embedding|\n",
      "+------------------+--------------+----+-----------+--------------------+\n",
      "|weaviate-cluster-1|  10.101.40.35|8080|hello there|[-0.09443893, 0.0...|\n",
      "|weaviate-cluster-2| 10.96.100.105|8080|hello there|[-0.09443893, 0.0...|\n",
      "|weaviate-cluster-3| 10.111.91.205|8080|hello there|[-0.09443893, 0.0...|\n",
      "|weaviate-cluster-4|  10.108.170.1|8080|hello there|[-0.09443893, 0.0...|\n",
      "|weaviate-cluster-5|10.100.180.155|8080|hello there|[-0.09443893, 0.0...|\n",
      "+------------------+--------------+----+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"hello there\"\n",
    "\n",
    "df = spark.createDataFrame([services[service] for service in services if service != \"grpc\"], input_schema)  ## spark df yarat\n",
    "df = df.withColumn(\"query\", F.col(\"query\").cast(StringType())).withColumn(\"query\", F.lit(query))            ## lit ile query'yi ekle\n",
    "df = df.withColumn(\"query_embedding\", generate_embedding_udf(F.col(\"query\")))                               ## udf ile embeddingleri al\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+----+-----------+--------------------+--------------------+\n",
      "|              name|            ip|port|      query|     query_embedding|            rag_text|\n",
      "+------------------+--------------+----+-----------+--------------------+--------------------+\n",
      "|weaviate-cluster-1|  10.101.40.35|8080|hello there|[-0.09443893, 0.0...|{NULL, 10.101.40....|\n",
      "|weaviate-cluster-2| 10.96.100.105|8080|hello there|[-0.09443893, 0.0...|{NULL, 10.96.100....|\n",
      "|weaviate-cluster-3| 10.111.91.205|8080|hello there|[-0.09443893, 0.0...|{NULL, 10.111.91....|\n",
      "|weaviate-cluster-4|  10.108.170.1|8080|hello there|[-0.09443893, 0.0...|{NULL, 10.108.170...|\n",
      "|weaviate-cluster-5|10.100.180.155|8080|hello there|[-0.09443893, 0.0...|{NULL, 10.100.180...|\n",
      "+------------------+--------------+----+-----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"rag_text\", search_weaviate_udf(F.col(\"name\"), F.col(\"ip\"), F.col(\"port\"), F.col(\"query_embedding\"))) \\\n",
    ".show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
