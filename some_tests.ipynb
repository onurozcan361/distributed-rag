{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/15 02:04:32 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "import subprocess\n",
    "import weaviate\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from scripts import weaviate_utils\n",
    "\n",
    "\n",
    "from weaviate.classes.query import MetadataQuery\n",
    "from scripts.weaviate_utils import get_external_ips\n",
    "\n",
    "\n",
    "input_schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"ip\", StringType(), True),\n",
    "    StructField(\"port\", StringType(), True),\n",
    "    StructField(\"query\", StringType(), True),\n",
    "])\n",
    "\n",
    "output_schema = StructType([\n",
    "    StructField(\"rag_text\", StringType(), True),\n",
    "    StructField(\"certainity\", FloatType(), True),\n",
    "    StructField(\"distance\", FloatType(), True),\n",
    "])\n",
    "\n",
    "\n",
    "vector_schema = ArrayType(FloatType())\n",
    "\n",
    "\n",
    "os.environ[\"COLLECTION_RETRIEVAL_STRATEGY\"] = \"LocalOnly\"\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"weaviate_deneme\").getOrCreate()\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "services = weaviate_utils.get_external_ips()\n",
    "grpc_ip = services[\"grpc\"][\"ip\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(query: str) -> list:\n",
    "    try:\n",
    "        q_embedding = embedding_model.encode(query).tolist()\n",
    "        return q_embedding\n",
    "    except Exception as e:\n",
    "        print(f\"err: {e}\")\n",
    "        return []\n",
    "\n",
    "generate_embedding_udf = F.udf(generate_embedding, vector_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_weaviate(cluster_name: str, cluster_ip: str, cluster_port: str, grpc_ip:str, query_vector: list) -> dict:\n",
    "    try:\n",
    "        with  weaviate.connect_to_custom(    \n",
    "            http_host=cluster_ip,\n",
    "            http_port=cluster_port,\n",
    "            http_secure=False,\n",
    "            grpc_host=grpc_ip,\n",
    "            grpc_port=50051,\n",
    "            grpc_secure=False)    as client:\n",
    "            \n",
    "            if not client.is_ready():\n",
    "                raise Exception(\"Weaviate instance is not ready.\")\n",
    "\n",
    "            chunks = client.collections.get(f\"dist_data_{cluster_name[-1]}\")\n",
    "    \n",
    "            results = chunks.query.near_vector(\n",
    "                query_vector,\n",
    "                limit=1,\n",
    "                return_metadata=MetadataQuery(distance=True, certainty=True),\n",
    "\n",
    "                \n",
    "            )\n",
    "\n",
    "            client.close()\n",
    "        \n",
    "        del chunks, client\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to Weaviate instance: {e}\")\n",
    "        return []\n",
    "    \n",
    "    if not results:\n",
    "        print(\"empty results\")\n",
    "        return []\n",
    "    \n",
    "    return_arr = []\n",
    "    for result in results.objects:\n",
    "        metadata = result.metadata\n",
    "        distance = metadata.distance\n",
    "        certainity = metadata.certainty\n",
    "        rag_text = result.properties['context']\n",
    "        \n",
    "        return_arr.append(\n",
    "            [rag_text, certainity, distance]\n",
    "        )\n",
    "\n",
    "        \n",
    "    return return_arr\n",
    "   \n",
    "\n",
    "\n",
    "search_weaviate_udf = F.udf(search_weaviate, ArrayType(output_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asgrich/anaconda3/envs/big-data/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py:193: ResourceWarning: unclosed file <_io.BufferedReader name=3>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/asgrich/anaconda3/envs/big-data/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py:193: ResourceWarning: unclosed file <_io.BufferedWriter name=5>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/asgrich/anaconda3/envs/big-data/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py:193: ResourceWarning: unclosed file <_io.BufferedReader name=3>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/asgrich/anaconda3/envs/big-data/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py:193: ResourceWarning: unclosed file <_io.BufferedWriter name=5>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Error connecting to Weaviate instance: Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\n",
      "\tstatus = StatusCode.UNKNOWN\n",
      "\tdetails = \"could not find class Dist_data_5 in schema\"\n",
      "\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"could not find class Dist_data_5 in schema\", grpc_status:2, created_time:\"2025-04-15T02:04:48.228342539+03:00\"}\"\n",
      ">.\n",
      "/home/asgrich/anaconda3/envs/big-data/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py:204: ResourceWarning: unclosed file <_io.BufferedReader name=3>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/asgrich/anaconda3/envs/big-data/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py:204: ResourceWarning: unclosed file <_io.BufferedWriter name=5>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+----------+\n",
      "|name              |ip           |port|rag_text                                                                                                                                                                                                                                                                                                                                                                          |certainity|distance  |\n",
      "+------------------+-------------+----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+----------+\n",
      "|weaviate-cluster-1|10.101.40.35 |8080|neurosis in freud and psychosis in lacan. in literary critical theory drawing on the french tradition of interest in the monstrous ( e. g., novelist louis - ferdinand celine ), and of the subject as grounded in \" filth \" ( e. g., psychoanalyst jacques lacan ),                                                                                                              |0.5994073 |0.8011854 |\n",
      "|weaviate-cluster-2|10.96.100.105|8080|to establish academies like the italian ones also took place in the 16th century, during the reign of king henry iii, especially through the work of the poet jean - antoine de baif, who founded an academy linked to the french crown. like its italian counterparts, it was primarily philological - philosophical in nature, but it                                           |0.64801383|0.70397234|\n",
      "|weaviate-cluster-3|10.111.91.205|8080|after an ineffective start, the academie royale was reorganized in 1661 by king louis xiv, whose aim was to control all the country ' s artistic activity, and in 1671, it came under the control of first minister of state jean - baptiste colbert, who confirmed le brun as director. together, they made it the                                                               |0.6471759 |0.7056481 |\n",
      "|weaviate-cluster-4|10.108.170.1 |8080|french crown. like its italian counterparts, it was primarily philological - philosophical in nature, but it also worked on concepts relating to the arts and sciences. although it developed intense activity with regular debates and theoretical production, defending classical principles, it lacked an educational structure and had a brief existence. the accademia di san|0.6500486 |0.6999027 |\n",
      "+------------------+-------------+----+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query = \"What is the capital of France?\"\n",
    "\n",
    "df = spark.createDataFrame([services[service] for service in services if service != \"grpc\"], input_schema)  ## spark df yarat\n",
    "df = df.withColumn(\"query\", F.col(\"query\").cast(StringType())).withColumn(\"query\", F.lit(query))            ## lit ile query'yi ekle\n",
    "df = df.withColumn(\"query_embedding\", generate_embedding_udf(F.col(\"query\")))                               ## udf ile embeddingleri al\n",
    "\n",
    "df = df.withColumn(\"result_struct\", search_weaviate_udf(\n",
    "    F.col(\"name\"),\n",
    "    F.col(\"ip\"),\n",
    "    F.col(\"port\"),\n",
    "    F.lit(grpc_ip),\n",
    "    F.col(\"query_embedding\")\n",
    "))\n",
    "\n",
    "df = df.withColumn(\"exploded_result\", F.explode(\"result_struct\")) \\\n",
    "  .withColumn(\"rag_text\", F.col(\"exploded_result.rag_text\")) \\\n",
    "    .withColumn(\"certainity\", F.col(\"exploded_result.certainity\")) \\\n",
    "    .withColumn(\"distance\", F.col(\"exploded_result.distance\")) \\\n",
    "    .select(\"name\", \"ip\", \"port\", \"rag_text\", \"certainity\", \"distance\") \\\n",
    "    \n",
    "\n",
    "df.show(truncate=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
